# import os

# import httpx
# from Chatmate.Utility.text_extraction import document_parser, extract_text, link_parser
# from Chatmate.models import Documents
# # from pymilvus import MilvusClient, DataType
# # from llama_index.core import VectorStoreIndex, Settings
# # from llama_index.embeddings.huggingface import HuggingFaceEmbedding
# # from llama_index.llms.ollama import Ollama
# # from llama_index.embeddings.ollama import OllamaEmbedding

# # def init_embeddings():
# #     """Initialize the LlamaIndex embedding model."""
# #     # # bge-base embedding model
# #     # Settings.embed_model = HuggingFaceEmbedding(model_name="BAAI/bge-base-en-v1.5")

# #     # # ollama
# #     # Settings.llm = Ollama(model="llama3", request_timeout=360.0)
# #     ollama_embedding = OllamaEmbedding(
# #     model_name="llama3",
# #     base_url="http://0.0.0.0:11434",
# #     ollama_additional_kwargs={"mirostat": 0},
# #     )
# #     Settings.embed_model = ollama_embedding
# #     Settings.llm = Ollama(model="llama3")

# # def init_milvus():
# #     """Initialize the Milvus client and create a collection."""
# #     CLUSTER_ENDPOINT = os.environ.get('MILVUS_API_ENDPOINT')
# #     TOKEN = os.environ.get('MILVUS_API_KEY')

# #     client = MilvusClient(
# #         uri=CLUSTER_ENDPOINT,
# #         token=TOKEN 
# #     )

# #     collection_name = 'document_embeddings'

# #     if not client.has_collection(collection_name):
# #         schema = MilvusClient.create_schema(
# #             auto_id=True,
# #             enable_dynamic_field=True,
# #         )
# #         schema.add_field(field_name="embedding", datatype=DataType.FLOAT_VECTOR, dim=384)
# #         schema.add_field(field_name="doc_id", datatype=DataType.INT64, is_primary=True)

# #         client.create_collection(
# #             collection_name=collection_name,
# #             schema=schema
# #         )

# #     return client

# # from llama_index.readers.web import SimpleWebPageReader


# # from llama_index.core import VectorStoreIndex, StorageContext
# # from llama_index.vector_stores.milvus import MilvusVectorStore

# # def get_vector_dim(example_vector):
# #     """Determine the dimension of vectors generated by the embedding model."""
# #     # Example to get vector dimensionality
# #     if example_vector is not None:
# #         return len(example_vector)
# #     else:
# #         raise ValueError("Example vector is None. Cannot determine vector dimension.")
# # from sentence_transformers import SentenceTransformer
# # def index_documents(client):
# #     """Index the documents into Milvus using LlamaIndex."""
# #     # Load documents
# #     init_embeddings()
# #     embedding_model = Settings.embed_model
# #     chunks = load_documents()
# #     model = SentenceTransformer('all-MiniLM-L6-v2')
# #     document_embeddings = model.encode(chunks)
# #     print("document_embeddings: ", document_embeddings)

# #     # # Assuming chunks contain vectors, get an example vector from the first chunk
# #     # example_vector = embedding_model.embed_query(chunks[0].text)  # or however you generate vectors

# #     # # Determine the dimension dynamically
# #     # dim = get_vector_dim(example_vector)

# #     # print("Document ID:", chunks[0].doc_id)
# #     # print("Vector Dimension:", dim)

# #     # vector_store = MilvusVectorStore(
# #     # uri=os.environ.get('MILVUS_API_ENDPOINT'), 
# #     # dim=1536, 
# #     # overwrite=True,
# #     # api_key=os.environ.get('MILVUS_API_KEY')
# #     # )

# #     # Configure MilvusVectorStore with dynamic dimension
# #     vector_store = MilvusVectorStore(
# #         uri="./milvus_demo.db",
# #         dim=768,  
# #         overwrite=True,
# #         embed_model=embedding_model
# #     )

# #     storage_context = StorageContext.from_defaults(vector_store=vector_store)
# #     index = VectorStoreIndex.from_documents(chunks, storage_context=storage_context)

# #     print("Indexing documents...", index)

# #     query_engine = index.as_query_engine()
    
# #     try:
# #         response = query_engine.query("What is Llama 3?")
# #         print("Response:", response)
# #         return index
# #     except httpx.ConnectError as e:
# #         print(f"Failed to connect to the query engine: {e}")
# #         return index
    
# #     # # Extract embeddings from the indexed documents
# #     # embeddings = [doc.embedding for doc in chunks]  # Extract embeddings directly from chunks

# #     # # Filter out documents with None embeddings
# #     # valid_data = [{"embedding": embedding.tolist()} for embedding in embeddings if embedding is not None]

# #     # if not valid_data:
# #     #     raise ValueError("No valid embeddings found for indexing.")

# #     # # Insert data into Milvus
# #     # try:
# #     #     client.insert(
# #     #         collection_name="document_embeddings",
# #     #         data=valid_data
# #     #     )
# #     #     print(f"Successfully indexed {len(valid_data)} documents into Milvus.")
# #     # except Exception as e:
# #     #     print(f"Failed to insert data into Milvus: {e}")



# # def drop_collection(client):
# #     """Drop the Milvus collection."""
# #     collection_name = "document_embeddings"
# #     if client.has_collection(collection_name):
# #         client.drop_collection(collection_name)
